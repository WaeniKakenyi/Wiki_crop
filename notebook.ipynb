{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting the data\n",
    "# import tarfile\n",
    "  \n",
    "# # open file\n",
    "# file = tarfile.open('data/wiki_crop.tar')\n",
    "  \n",
    "# # print file names\n",
    "# print(file.getnames())\n",
    "  \n",
    "# # extract files\n",
    "# file.extractall('./')\n",
    "  \n",
    "# # close file\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Conv2D, Flatten, Dense, BatchNormalization\n",
    "from keras.layers import Reshape, concatenate, LeakyReLU, Lambda\n",
    "from keras.layers import Activation, UpSampling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing import image\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(taken, dob):\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "    # assume the photo was taken in the middle of the year\n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(wiki_dir, dataset=\"wiki\"):\n",
    "     # Load the wiki.mat file\n",
    "     meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
    "     # Load the list of all files\n",
    "     full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
    "     # List of Matlab serial date numbers\n",
    "     dob = meta[dataset][0, 0][\"dob\"][0]\n",
    "     # List of years when photo was taken\n",
    "     photo_taken = meta[dataset][0, 0][\"photo_taken\"][0] # year\n",
    "     # Calculate age for all dobs\n",
    "     age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "     # Create a list of tuples containing a pair of an image path and age\n",
    "     images = []\n",
    "     age_list = []\n",
    "     for index, image_path in enumerate(full_path):\n",
    "          images.append(image_path[0])\n",
    "          age_list.append(age[index])\n",
    "     # Return a list of all images and respective age\n",
    "     return images, age_list\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder network\n",
    "It encodes an image to a latent/hidden vector  (random variable that can't be measured directly)\n",
    "- latent vectors are attributed to:\n",
    "    1. We map higher dimensional data to a lower dimensional data with no prior convictions of how the mapping will be done. The NN trains itself for the best configuration.\n",
    "    2. We cannot manipulate this lower dimensional data. Thus it is \"hidden from us.\n",
    "    3. As we do not know what each dimension means, it is \"hidden\" from us.\n",
    "- `Conv2D layer` - It is responsible for extracting features from the input data. It does this by sliding a small kernel over the input data and performing element-wise multiplications with the elements of the filter followed by summing up all of the products. The process is repeated for every position of the filter on the input data resulting in an output called a feature map.\n",
    "    - Each filter has its own set of weights learned during the training process and are shared across all positions of the input data. e.g. if the input data is an image, a convolutional layer might learn to recognize edges, corners, or other simple patterns in the image. These low-level features can then be combined by higher layers in the model to recognize more complex patterns, such as objects or scenes.\n",
    "    - hyperparameters:\n",
    "    1. `filters` = the number of filters to be applied in the layer. Each filter is a small tensor(multi-dimensional array) of weights with the same depth as the input data i.e channels size. Increasing the number of filters increases the capacity of the model to learn complex features from the data, but also increases the number of parameters in the model and the amount of computation required. Choosing the right number of filters is a trade-off between model performance and efficiency.\n",
    "    2. `Kernel_size` = The size of the kernel being slid across the window. It is a square e.g 5 is (5,5)\n",
    "    3. `Strides` = How many spaces it shall skip, also a square. An integer or tuple/list of 2 integers, specifying the strides of\n",
    "    the convolution along the height and width. \n",
    "    4. `padding` = addition of extra pixels around the edges of the input data. If the padding parameter is set to 'same', it means that the output feature map has the same spatial dimensions (i.e. height and width) as the input.For example, if the input data is an image with spatial dimensions 64x64, and the kernel size of the convolutional layer is 5x5 with a stride of 2, then padding of 2 rows and 2 columns would be added to the input image so that the output feature map has the same spatial dimensions as the input.\n",
    "- `LeakyReLu` - activation function that has a small slope for negative input values, rather than zero as in the case of traditional ReLU. LeakyReLU(x) = x for x >= 0 and LeakyReLU(x) = alpha * x for x < 0. Alpha is a small value. Leaky ReLU addresses the dying ReLU problem (where model has an output of 0 for all inputs) by allowing a small gradient for negative input values, which allows the weights of the neuron to be updated and the neuron to \"recover.\" \n",
    "- `BatchNormalization` - normalizes the activations of the previous layer at each batch, i.e. it standardizes the mean and variance of the activations. It is typically applied to the outputs of a convolutional or fully connected (FC) layer, before the activation function. After the convolutional layer, the output is passed through a BatchNormalization layer, which normalizes the activations of the previous layer using the mean and variance of the activations, computed across the current batch of training data.\n",
    "    -  The purpose of batch normalization is to improve the stability and performance of neural networks. It does this by normalizing the activations of the previous layer at each batch, which can help to reduce the internal covariate shift and improve the gradient flow through the network. It has been shown to improve the training and generalization of deep neural networks on a wide range of tasks.\n",
    "- `Flatten` - It converts this multi-dimensional array into a flat 1D array, with the shape (batch_size, num_features), where num_features is the total number of elements in the original array. The Flatten layer is often used after the convolutional layers of a CNN to prepare the output for the fully connected (FC) layers, which expect a 1D array as input. It is also sometimes used after the pooling layers of a CNN to reduce the spatial resolution of the output and reduce the number of parameters in the model.\n",
    "    - For example, if the input to the Flatten layer has shape (batch_size, height, width, channels), then the output of the Flatten layer will have shape (batch_size, height * width * channels).\n",
    "- `Dense` - This is a layer where all the units(neurons) in the previous layer, and the connections are weighted.   \n",
    "    - When units=1, we are applying a linear transformation unlike when units=4096\n",
    "    - The purpose of a dense layer is to combine the features learned by the previous layers and make predictions. Dense layers are often used as the output layer of a neural network, but they can also be used in the hidden layers of the network.\n",
    "    - Increasing the number of units in a dense layer (also called the width of the layer) can increase the capacity of the model, allowing it to learn more complex patterns in the data. However, it can also increase the risk of overfitting, particularly if the model is not regularized properly.\n",
    "    - On the other hand, decreasing the number of units in a dense layer can decrease the capacity of the model and reduce the risk of overfitting. However, it can also limit the ability of the model to learn complex patterns in the data, which can degrade the performance of the model.\n",
    "    - In general, it is recommended to start with a small number of units and increase the width of the layer as needed, while keeping an eye on the training and validation error. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "def build_encoder():\n",
    "    input_layer = Input(64,64,3)\n",
    "\n",
    "    # 1st Convolutional Block \n",
    "    enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 2nd Convolutional Block\n",
    "    enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 3rd Convolutional Block\n",
    "    enc = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 4th Convolutional Block\n",
    "    enc = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # Flatten layer\n",
    "    enc = Flatten()(enc)\n",
    "\n",
    "    # 1st Fully Connected Layer\n",
    "    enc = Dense(4096)(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    enc = Dense(100)(enc)\n",
    "\n",
    "    # Create a model\n",
    "    model = Model(inputs=[input_layer], outputs=[enc])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator network\n",
    "It is a CNN that takes 100-dimensional vector z and generates an image with a dimension (64,64,3)\n",
    "- `Droupout` - It is a regularization layer that randomly sets a fraction of the input units to zero during training. \n",
    "    - It takes a a fraction of the units to dropout as input, which is specified by the rate parameter\n",
    "    - E.g. Dropout(0.2) drops 20% of the input units which is equivalent to setting a random 20% of the inputs to zero\n",
    "    - It is often used after the `Dense` layer to reduce the risk of overfitting\n",
    "    - During training, the Dropout layer randomly sets a fraction of the input units to zero, which has the effect of reducing the complexity of the model and preventing the units from co-adapting too much.\n",
    "    - During evaluation or inference, the Dropout layer is usually disabled, and the input is passed through unchanged. This allows the model to make predictions using all the units, which can improve the performance of the model.\n",
    "- `Upsampling2D` - It increases the resolution of the input tensors by upsampling the data along the spatial (height and width) dimensions. \n",
    "    - It is the process of repeating rows a specified number of times x and repeating the columns a specified number of times y\n",
    "    - `size` = Specifies the upsampling factors along the height and width dimensions. e.g. 2 upsamples the input by a factor of 2 aling both dimensions which is equal to doubling the resolution of the input tensor\n",
    "    - It is often used in conjunction with convolutional layers to increase the resolution of the feature maps\n",
    "- `Activation` - It applies element-wise activation function to the input. It helps introduce non-linearity to a NN and allow it to learn more complex patterns in the data\n",
    "    - `name` = Name of the acivation function to use e.g. tanh, sigmoid etc\n",
    "    - `tanh activation` = It maps the input to the range [-1,1]. \n",
    "    - `sigmoid activation` = It maps the input to the range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    latent_dims = 100\n",
    "    num_classes = 6\n",
    "    # Input layer for vector z - 1D\n",
    "    input_z_noise = Input(shape=(latent_dims, )) # Model expects a tensor with 100 elements as input, TensorShape([None, 100])\n",
    "    # Input layer for conditioning variable\n",
    "    input_label = Input(shape=(num_classes, )) #TensorShape([None, 6])\n",
    "    # Concantenate inputs along the channel dimension and generate a concatenated tensor\n",
    "    x = concatenate([input_z_noise, input_label]) # TensorShape([None, 106])\n",
    "\n",
    "    # 1st Desnse layer\n",
    "    x = Dense(2048, input_dim=latent_dims+num_classes)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # 2nd Dense layer\n",
    "    x = Dense(256 * 8 * 8)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Reshape the output to a 3D tensor with dimensions (8,8,256)\n",
    "    x = Reshape((8, 8, 256))(x) # output is a tensor (batch_size, 8,8,256)\n",
    "\n",
    "    # 1st Upsampling layer\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=128, kernel_size=5, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 2nd Upsampling layer\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=64, kernel_size=5, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd Upsampling layer\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=3, kernel_size=5, padding='same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Network\n",
    "It is a CNN that tries to differentiate between the real data and the data generated by the generator network. The discriminator network tries to put the incoming data into predefined categories. It can either perform multi-class classification or binary classification. Generally, in GANs binary classification is performed.It processes an image and outputs a probability of the image belonging to a particular class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expand_label_input function\n",
    "def expand_label_input(x):\n",
    "    \"\"\"\n",
    "    It takes an input tensor x and expands its dimensions \n",
    "    to match the shape of the target tensor\n",
    "    The expand_dims function is used to insert a new axis at \n",
    "    a specified position in the tensor\n",
    "    The axis parameter specifies the position of the new axis \n",
    "    with 0 == first axis and K.ndim(x)-1 to the last axis\n",
    "    The function is expanding the input tensor x aling the first\n",
    "    and second axes by inserting two new axes at position 1 and 2\n",
    "    The tile function is used to repeat the input tensor along \n",
    "    specified dimensions. \n",
    "    The function repeats the input tensor along the first,second\n",
    "    and fourth dimensions to match the shape of the target tensor\n",
    "    with shape (batch_size, 32,32,num_channels)\n",
    "    \"\"\"\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.tile(x, [1, 32, 32, 1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    # Input image shape\n",
    "    input_shape = (64, 64, 3)\n",
    "    # Input conditioning variable shape\n",
    "    label_shape = (6,)\n",
    "    # Two input layers\n",
    "    image_input = Input(shape=input_shape) # TensorShape([None, 64, 64, 3])\n",
    "    label_input = Input(shape=label_shape) #TensorShape([None, 6])\n",
    "\n",
    "    # 1st Convolution layer\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(image_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Expand label_input to have a shape of (32,32,6)\n",
    "    label_input1 = Lambda(expand_label_input)(label_input) # TensorShape([None, 32, 32, 6])\n",
    "\n",
    "    # Concatenate the transformed label tensor and the output of the last convolution layer\n",
    "    x = concatenate([x, label_input1], axis=3) # TensorShape([None, 32, 32, 70])\n",
    "\n",
    "    # 2nd Convolution layer\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd Convolution layer\n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 4th Convolution layer\n",
    "    x = Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Flatten layer\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = Dense(1, activation='sigmoid')(x) # outputs a probability\n",
    "\n",
    "    model = Model(inputs=[image_input, label_input], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the cGAN\n",
    "Three steps involved:\n",
    "    - Training the cGAN - the NNs\n",
    "    - Initial latent vector approximation\n",
    "    - Latent vector optimization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Training the cGAN\n",
    "- `Adam` - It is an optimization algorithm that is used to update the parameters (weights) of a neural network during training\n",
    "    - It uses an adaptive learning rate that decreases over time. It estimates the mean and variance of the gradient for eaach parameter and upates the parameters. \n",
    "    -  The gradient is a vector that points in the direction of the steepest increase of the loss function and has the same shape as the parameters. The optimizer uses the gradient to adjust the parameters in the opposite direction, which should reduce the value of the loss function.\n",
    "    - lr=0.0002: The `learning rate`.\n",
    "    - beta_1=0.5: The `exponential decay rate` for the mean.\n",
    "    - beta_2=0.999: The `exponential decay rate` for the variance.\n",
    "    - epsilon=10e-8: The small value used to `prevent division by zero.`\n",
    "- `Adversarial model` - is a combination of the generator and discriminator\n",
    "    - The adversarial model is trained by alternating between training the generator to generate better fake images and training the discriminator to better distinguish between real and fake images.\n",
    "    - The `discriminator.trainable` attribute is set to `False`, which means that the weights of the discriminator model will not be updated during training of the adversarial model. This is because the goal of the adversarial model is to train the generator to generate better fake images, not to update the weights of the discriminator.\n",
    "    - The adversarial model takes in the `input_z_noise` and `input_label` tensors as input and `outputs the valid tensor`.\n",
    "- `Normalization` - Ithelps the GAN model to learn more effectively, as the model will be able to learn from data that is centered around 0 and has small values, rather than large values that may be harder for the model to learn from.\n",
    "    - Normalization can help the model converge faster and perform better. \n",
    "    - In this specific case, the images are being normalized by scaling them to a range of [-1, 1]. This is often done in machine learning when the input data has values in a different range, such as [0, 255] for pixel values of images, in order to make the data easier to work with and improve model performance. It is not necessary to always subtract by 1, it just depends on the range of the input data and what is most appropriate for the specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_category(ages):\n",
    "    \"\"\" \n",
    "    Function to convert the ages into different categories\n",
    "    \"\"\"\n",
    "    ages_list = []\n",
    "    for age in ages:\n",
    "        if 0 < age <= 18:\n",
    "            age_category = 0\n",
    "        elif 18 < age <= 29:\n",
    "            age_category = 1\n",
    "        elif 29 < age <= 39:\n",
    "            age_category = 2\n",
    "        elif 39 < age <= 49:\n",
    "            age_category = 3\n",
    "        elif 49 < age <= 59:\n",
    "            age_category = 4\n",
    "        elif age >= 60:\n",
    "            age_category = 5\n",
    "        ages_list.append(age_category)\n",
    "    return ages_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, image_paths, image_shape):\n",
    "    \"\"\" \n",
    "    This function loads a set of images from a given directory,\n",
    "    resizes them to the given shape and concantenates them into \n",
    "    a single tensor\n",
    "    \"\"\"\n",
    "    images = None\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        try:\n",
    "            # Load image\n",
    "            loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n",
    "            # Convert PIL image to numpy ndarray\n",
    "            loaded_image = image.img_to_array(loaded_image)\n",
    "            # Add another dimension (Add batch dimension)\n",
    "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
    "            # Concatenate all images into one tensor\n",
    "            if images is None:\n",
    "                images = loaded_image\n",
    "            else:\n",
    "                # print(False)\n",
    "                images = np.concatenate([images, loaded_image], axis=0)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", i, e)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save a rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(callback, name, value, batch_no):\n",
    "  writer = tf.summary.create_file_writer(\"/tmp/mylogs\")\n",
    "  with writer.as_default():\n",
    "    for step in range(100):\n",
    "      # other model code would go here\n",
    "      tf.summary.scalar(\"my_metric\", 0.5, step=step)\n",
    "      writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = r\"C:/Users/meshw/Desktop/Moringa/phase_5/project/Wiki_crop\"\n",
    "# wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
    "\n",
    "# Define hyperparameters\n",
    "data_dir = os.getcwd()\n",
    "wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "image_shape = (64, 64, 3)\n",
    "z_shape = 100\n",
    "TRAIN_GAN = True\n",
    "TRAIN_ENCODER = False\n",
    "TRAIN_GAN_WITH_FR = False\n",
    "fr_image_shape = (192, 192, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "from tensorboard import summary\n",
    "# Optimizer for the discriminator network\n",
    "dis_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
    "# Optimizer for the generator network\n",
    "gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
    "# Optimizer for the adversarial network\n",
    "adversarial_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
    "\n",
    "# Build and compile the discriminator network\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n",
    "# Build and compile the generator network\n",
    "generator = build_generator()\n",
    "generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
    "\n",
    "# Build and compile the adversarial model\n",
    "discriminator.trainable = False # it is important to ensure the discriminator is not training when the generator is training\n",
    "input_z_noise = Input(shape=(100,)) # TensorShape([None, 100])\n",
    "input_label = Input(shape=(6,)) # TensorShape([None, 6])\n",
    "recons_images = generator([input_z_noise, input_label]) # These are the fake images generated by the generator network of shape TensorShape([None, 64, 64, 3])\n",
    "valid = discriminator([recons_images, input_label]) \n",
    "adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n",
    "adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
    "\n",
    "# Using Tensorboard to store losses\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n",
    "tensorboard.set_model(generator)\n",
    "tensorboard.set_model(discriminator)\n",
    "\n",
    "# Load images and ages from the dataset\n",
    "images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
    "    \n",
    "# Convert age to category\n",
    "age_cat = age_to_category(age_list)\n",
    "\n",
    "# Convert the age categories to one-hot encoded vectors\n",
    "final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1]) # Convert the shape to (62328, 1)\n",
    "classes = len(set(age_cat)) # Store unique classes\n",
    "y = to_categorical(final_age_cat, num_classes=len(set(age_cat))) # Returns a 2D array containing the one-hot encoded vectors and shape (62328, 7) \n",
    "\n",
    "# Read all images and create an ndarray\n",
    "loaded_images = load_images(wiki_dir, images[:20], (image_shape[0], image_shape[1]))\n",
    "\n",
    "## Implement label smoothing\n",
    "real_labels = np.ones((batch_size, 1), dtype = np.float32) * 0.9\n",
    "fake_labels = np.zeros((batch_size, 1), dtype = np.float32) * 0.1\n",
    "# Epochs\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:{}\".format(epoch))\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    number_of_batches = int(len(loaded_images) / batch_size)\n",
    "    print(\"Number of batches:\", number_of_batches)\n",
    "    for index in range(number_of_batches):\n",
    "        print(\"Batch:{}\".format(index + 1))\n",
    "        images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
    "        images_batch = (images_batch / 255.0 - 0.5) / 0.5 # Normalizes the pixel values to be between 1 and -1\n",
    "        images_batch = images_batch.astype(np.float32) # Converts data type to float\n",
    "        y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "        z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "        initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "        d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n",
    "        # Again sample a batch of noise vectors from a Gaussian(normal) distribution \n",
    "        z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "        # Samples a batch of random age values\n",
    "        random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
    "        # Convert the random age values to one-hot encoders\n",
    "        random_labels = to_categorical(random_labels, 6)\n",
    "        \n",
    "        # Train the generator network\n",
    "        g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], np.ones((batch_size,1))) # Sets the likelihood that ist predictions are equal to 1\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        print(\"d_loss:{}\".format(d_loss))\n",
    "        print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "\n",
    "        write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
    "        write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            images_batch = loaded_images[0:batch_size]\n",
    "            images_batch = (images_batch / 255.0 - 0.5) / 0.5\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "            y_batch = y[0:batch_size]\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "            gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "            for i, img in enumerate(gen_images[:5]):\n",
    "                save_rgb_img(img, path=os.path.join(os.getcwd(), \"results/img_{}_{}.png\".format(epoch, i)))\n",
    "\n",
    "        # Save weights only\n",
    "        generator.save_weights(\"generator.h5\")\n",
    "        discriminator.save_weights(\"discriminator.h5\")\n",
    "        # Save architecture and weights both\n",
    "        generator.save(\"generator.h5\")\n",
    "        discriminator.save(\"discriminator.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Epochs\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"Epoch:{}\".format(epoch))\n",
    "#     gen_losses = []\n",
    "#     dis_losses = []\n",
    "#     number_of_batches = int(len(loaded_images) / batch_size)\n",
    "#     print(\"Number of batches:\", number_of_batches)\n",
    "#     for index in range(number_of_batches):\n",
    "#         print(\"Batch:{}\".format(index + 1))\n",
    "#         images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
    "#         images_batch = (images_batch / 255.0 - 0.5) / 0.5 # Normalizes the pixel values to be between 1 and -1\n",
    "#         images_batch = images_batch.astype(np.float32) # Converts data type to float\n",
    "#         y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "#         z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "#         initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "#         d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
    "#         d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n",
    "#         # Again sample a batch of noise vectors from a Gaussian(normal) distribution \n",
    "#         z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "#         # Samples a batch of random age values\n",
    "#         random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
    "#         # Convert the random age values to one-hot encoders\n",
    "#         random_labels = to_categorical(random_labels, 6)\n",
    "        \n",
    "#         # Train the generator network\n",
    "#         g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], np.ones((batch_size,1))) # Sets the likelihood that ist predictions are equal to 1\n",
    "        \n",
    "#         # Calculate and print the losses\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "#         print(\"d_loss:{}\".format(d_loss))\n",
    "#         print(\"g_loss:{}\".format(g_loss))\n",
    "        \n",
    "#         # Add losses to their respective lists\n",
    "#         gen_losses.append(g_loss)\n",
    "#         dis_losses.append(d_loss)\n",
    "\n",
    "#         # Write losses to Tensorboard for visualization\n",
    "#         write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
    "#         write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
    "\n",
    "#         # Sample and save images after every 10 epochs\n",
    "#         if epoch % 10 == 0:\n",
    "#             images_batch = loaded_images[0:batch_size]\n",
    "#             images_batch = images_batch / 127.5 - 1.0\n",
    "#             images_batch = images_batch.astype(np.float32)\n",
    "#             y_batch = y[0:batch_size]\n",
    "#             z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "#             gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "#             for i, img in enumerate(gen_images[:5]):\n",
    "#                 save_rgb_img(img, path=\"results/img_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "#         # Save weights only\n",
    "#         generator.save_weights(\"generator.h5\")\n",
    "#         discriminator.save_weights(\"discriminator.h5\")\n",
    "#         # Save architecture and weights both\n",
    "#         generator.save(\"generator.h5\")\n",
    "#         discriminator.save(\"discriminator.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial latent vector approximation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a68e12a0c1e00f773e0870b765910b80f9f6f42cbc49a01ab803126915e37a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
